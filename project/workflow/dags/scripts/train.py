from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import pandas as pd
import polars as pl
import numpy as np
import re
import pickle
import json
import os
import sys
import hashlib
from datetime import datetime
from minio import Minio
from io import BytesIO
from typing import Dict, Tuple, Optional


def get_minio_client(
    endpoint: str = 'minio:9000',
    access_key: str = 'minio',
    secret_key: str = 'minio123',
    secure: bool = False
) -> Minio:
    """
    MinIO í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        endpoint: MinIO ì—”ë“œí¬ì¸íŠ¸
        access_key: ì ‘ê·¼ í‚¤
        secret_key: ì‹œí¬ë¦¿ í‚¤
        secure: SSL ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        Minio: MinIO í´ë¼ì´ì–¸íŠ¸ ê°ì²´
    """
    return Minio(
        endpoint,
        access_key=access_key,
        secret_key=secret_key,
        secure=secure
    )


def extract_phase(apartment_name):
    """
    ì•„íŒŒíŠ¸ëª…ì—ì„œ ì°¨ìˆ˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 'ë‚¨ì™¸í‘¸ë¥´ì§€ì˜¤1ì°¨' -> '1ì°¨', 'ë‚¨ìš´í•™ì„±íƒ€ìš´' -> None
    """
    if pd.isna(apartment_name):
        return None
    match = re.search(r'(\d+ì°¨)$', str(apartment_name))
    return match.group(1) if match else None


def remove_phase(apartment_name):
    """
    ì•„íŒŒíŠ¸ëª…ì—ì„œ ì°¨ìˆ˜ ì •ë³´ë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 'ë‚¨ì™¸í‘¸ë¥´ì§€ì˜¤1ì°¨' -> 'ë‚¨ì™¸í‘¸ë¥´ì§€ì˜¤', 'ë‚¨ìš´í•™ì„±íƒ€ìš´' -> 'ë‚¨ìš´í•™ì„±íƒ€ìš´'
    """
    if pd.isna(apartment_name):
        return apartment_name
    return re.sub(r'\d+ì°¨$', '', str(apartment_name)).strip()


def split_lot_number(lot):
    """
    ì§€ë²ˆì„ ë³¸ë²ˆê³¼ ë¶€ë²ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
    '506-1' -> (506, 1)
    '379' -> (379, 0)
    """
    if pd.isna(lot):
        return 0, 0
    
    lot_str = str(lot).strip()
    if '-' in lot_str:
        parts = lot_str.split('-', 1)
        main = int(parts[0]) if parts[0].isdigit() else 0
        sub = int(parts[1]) if parts[1].isdigit() else 0
        return main, sub
    else:
        main = int(lot_str) if lot_str.isdigit() else 0
        return main, 0


def load_data_from_minio(
    client: Minio,
    bucket: str,
    object_name: str,
    limit: Optional[int] = None
) -> pl.DataFrame:
    """
    MinIOì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        client: MinIO í´ë¼ì´ì–¸íŠ¸
        bucket: ë²„í‚· ì´ë¦„
        object_name: ê°ì²´ ì´ë¦„
        limit: ì½ì„ ìµœëŒ€ í–‰ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        
    Returns:
        pl.DataFrame: ë¡œë“œëœ ë°ì´í„°í”„ë ˆì„
    """
    try:
        response = client.get_object(bucket, object_name)
        object_data = BytesIO(response.read())
        object_data.seek(0)
        
        df = pl.read_csv(
            object_data,
            schema_overrides={
                'ê±°ë˜ê¸ˆì•¡': pl.Utf8,
                'ì¸µ': pl.Utf8
            }
        )
        
        if limit:
            df = df[:limit]
            
        response.close()
        response.release_conn()
        
        return df
    except Exception as e:
        raise Exception(f"MinIOì—ì„œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


def preprocess_data(df: pl.DataFrame) -> Tuple[pd.DataFrame, Dict[str, LabelEncoder]]:
    """
    ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        Tuple[pd.DataFrame, Dict[str, LabelEncoder]]: ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ LabelEncoder ë”•ì…”ë„ˆë¦¬
    """
    # ì°¨ìˆ˜ ì¶”ì¶œ
    df = df.with_columns(
        pl.col('ì•„íŒŒíŠ¸').map_elements(extract_phase, return_dtype=pl.Utf8).alias('ì°¨ìˆ˜')
    )
    
    # ì§€ë²ˆ ë¶„ë¦¬
    df = df.with_columns([
        pl.col('ì§€ë²ˆ').map_elements(
            lambda x: split_lot_number(x)[0] if x else 0,
            return_dtype=pl.Int64
        ).alias('ì§€ë²ˆ_ë³¸ë²ˆ'),
        pl.col('ì§€ë²ˆ').map_elements(
            lambda x: split_lot_number(x)[1] if x else 0,
            return_dtype=pl.Int64
        ).alias('ì§€ë²ˆ_ë¶€ë²ˆ')
    ])
    
    # ì•„íŒŒíŠ¸ëª… ì •ì œ
    df = df.with_columns(
        pl.col('ì•„íŒŒíŠ¸').map_elements(remove_phase, return_dtype=pl.Utf8).alias('ì•„íŒŒíŠ¸_ì •ì œ')
    )
    
    # ì°¨ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.with_columns(
        pl.col('ì°¨ìˆ˜').fill_null('ì—†ìŒ')
    )
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    n_df = df[['ì§€ì—­ì½”ë“œ', 'ë²•ì •ë™', 'ì•„íŒŒíŠ¸_ì •ì œ', 'ì°¨ìˆ˜', 'ì§€ë²ˆ_ë³¸ë²ˆ', 'ì§€ë²ˆ_ë¶€ë²ˆ', 
               'ì „ìš©ë©´ì ', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'ê±°ë˜ê¸ˆì•¡']]
    
    # Polarsë¥¼ Pandasë¡œ ë³€í™˜
    n_df_pd = n_df.to_pandas()
    
    # LabelEncoder ìƒì„± ë° ì ìš©
    encoders = {}
    le_a = LabelEncoder()
    le_b = LabelEncoder()
    le_c = LabelEncoder()
    
    n_df_pd['ë²•ì •ë™'] = le_a.fit_transform(n_df_pd['ë²•ì •ë™'])
    n_df_pd['ì°¨ìˆ˜'] = le_b.fit_transform(n_df_pd['ì°¨ìˆ˜'])
    n_df_pd['ì•„íŒŒíŠ¸_ì •ì œ'] = le_c.fit_transform(n_df_pd['ì•„íŒŒíŠ¸_ì •ì œ'])
    
    encoders['ë²•ì •ë™'] = le_a
    encoders['ì°¨ìˆ˜'] = le_b
    encoders['ì•„íŒŒíŠ¸_ì •ì œ'] = le_c
    
    # ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    n_df_pd['ì§€ë²ˆ_ë³¸ë²ˆ'] = n_df_pd['ì§€ë²ˆ_ë³¸ë²ˆ'].fillna(0).astype(int)
    n_df_pd['ì§€ë²ˆ_ë¶€ë²ˆ'] = n_df_pd['ì§€ë²ˆ_ë¶€ë²ˆ'].fillna(0).astype(int)
    n_df_pd['ê±´ì¶•ë…„ë„'] = n_df_pd['ê±´ì¶•ë…„ë„'].fillna(0).astype(int)
    n_df_pd['ì§€ì—­ì½”ë“œ'] = n_df_pd['ì§€ì—­ì½”ë“œ'].fillna(0).astype(int)
    
    n_df_pd['ì¸µ'] = pd.to_numeric(
        n_df_pd['ì¸µ'].replace(' ', np.nan).replace('', np.nan),
        errors='coerce'
    ).fillna(0).astype(int)
    
    n_df_pd['ê±°ë˜ê¸ˆì•¡'] = pd.to_numeric(
        n_df_pd['ê±°ë˜ê¸ˆì•¡'].astype(str).str.replace(',', ''),
        errors='coerce'
    ).fillna(0).astype(int)
    
    return n_df_pd, encoders


def save_artifacts_to_minio(
    client: Minio,
    bucket: str,
    model: RandomForestRegressor,
    encoders: Dict[str, LabelEncoder],
    metrics: Dict[str, float],
    model_name: str = "apartment-price-prediction",
    version: Optional[str] = None,
    hyperparameters: Optional[Dict] = None,
    data_info: Optional[Dict] = None
) -> str:
    """
    ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ê°ì²´ë¥¼ MinIOì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (Phase 1: í•„ìˆ˜ í•­ëª© ì ìš©)
    
    Args:
        client: MinIO í´ë¼ì´ì–¸íŠ¸
        bucket: ë²„í‚· ì´ë¦„
        model: í•™ìŠµëœ ëª¨ë¸
        encoders: LabelEncoder ë”•ì…”ë„ˆë¦¬
        metrics: í‰ê°€ ë©”íŠ¸ë¦­
        model_name: ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "apartment-price-prediction")
        version: ëª¨ë¸ ë²„ì „ (Noneì´ë©´ ìë™ ìƒì„±)
        hyperparameters: í•˜ì´í¼íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        data_info: ë°ì´í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        str: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
    """
    try:
        # ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
        found = client.bucket_exists(bucket)
        if not found:
            client.make_bucket(bucket)
            print(f"âœ… ë²„í‚· ìƒì„± ì™„ë£Œ: {bucket}")
        else:
            print(f"âœ… ë²„í‚· ì´ë¯¸ ì¡´ì¬: {bucket}")
        
        # 1. ë²„ì „ ê´€ë¦¬ (í•„ìˆ˜)
        if version is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            version = f"v1.0.0_{timestamp}"
        
        # 4. êµ¬ì¡°í™”ëœ ê²½ë¡œ (í•„ìˆ˜): {model_name}/{version}/
        base_path = f"{model_name}/{version}"
        
        # 2. ë©”íƒ€ë°ì´í„° ìƒì„± (í•„ìˆ˜)
        metadata = {
            "model_name": model_name,
            "version": version,
            "created_at": datetime.now().isoformat(),
            "metrics": metrics,
            "model_type": type(model).__name__,
            "hyperparameters": hyperparameters or {},
            "data_info": data_info or {},
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}",
            "git_commit": os.getenv("GIT_COMMIT", "unknown")
        }
        
        # íŒŒì¼ ì €ì¥ í—¬í¼ í•¨ìˆ˜
        def save_file(file_name: str, data: bytes, content_type: str = 'application/octet-stream'):
            """MinIOì— íŒŒì¼ì„ ì €ì¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
            client.put_object(
                bucket,
                f"{base_path}/{file_name}",
                BytesIO(data),
                length=len(data),
                content_type=content_type
            )
        
        # ëª¨ë¸ ì €ì¥
        model_buffer = BytesIO()
        pickle.dump(model, model_buffer)
        model_data = model_buffer.getvalue()
        save_file("model.pkl", model_data)
        
        # ì¸ì½”ë” ì €ì¥
        encoders_buffer = BytesIO()
        pickle.dump(encoders, encoders_buffer)
        save_file("encoders.pkl", encoders_buffer.getvalue())
        
        # ë©”íŠ¸ë¦­ ì €ì¥ (JSON í˜•íƒœë¡œ)
        metrics_json = json.dumps(metrics, indent=2, ensure_ascii=False).encode('utf-8')
        save_file("metrics.json", metrics_json, 'application/json')
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata_json = json.dumps(metadata, indent=2, ensure_ascii=False).encode('utf-8')
        save_file("metadata.json", metadata_json, 'application/json')
        
        # 3. ì²´í¬ì„¬ ì €ì¥ (í•„ìˆ˜)
        model_hash = hashlib.sha256(model_data).hexdigest()
        checksum = {"model_sha256": model_hash}
        checksum_json = json.dumps(checksum).encode('utf-8')
        save_file("checksum.json", checksum_json, 'application/json')
        
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {bucket}/{base_path}/")
        print(f"   ë²„ì „: {version}")
        print(f"   ë©”íŠ¸ë¦­: RÂ²={metrics.get('r2', 0):.4f}, RMSE={metrics.get('rmse', 0):,.0f}")
        
        return f"{bucket}/{base_path}"
        
    except Exception as e:
        raise Exception(f"MinIOì— ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")


def save_artifacts_with_mlflow(
    mlflow_tracking_uri: str,
    model: RandomForestRegressor,
    encoders: Dict[str, LabelEncoder],
    metrics: Dict[str, float],
    hyperparameters: Dict,
    data_info: Dict,
    model_name: str = "apartment-price-prediction",
    experiment_name: str = "apartment-price-prediction",
    use_mlflow: bool = True,
    fallback_to_minio: bool = True,
    minio_client: Optional[Minio] = None,
    minio_bucket: Optional[str] = None
) -> Dict[str, str]:
    """
    MLflowë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì €ì¥ (í•˜ì´ë¸Œë¦¬ë“œ: MLflow ì‹¤íŒ¨ ì‹œ MinIOë¡œ í´ë°±)
    
    Args:
        mlflow_tracking_uri: MLflow ì„œë²„ URI
        model: í•™ìŠµëœ ëª¨ë¸
        encoders: LabelEncoder ë”•ì…”ë„ˆë¦¬
        metrics: í‰ê°€ ë©”íŠ¸ë¦­
        hyperparameters: í•˜ì´í¼íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        data_info: ë°ì´í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬
        model_name: ëª¨ë¸ ì´ë¦„
        experiment_name: ì‹¤í—˜ ì´ë¦„
        use_mlflow: MLflow ì‚¬ìš© ì—¬ë¶€
        fallback_to_minio: MLflow ì‹¤íŒ¨ ì‹œ MinIO í´ë°± ì—¬ë¶€
        minio_client: MinIO í´ë¼ì´ì–¸íŠ¸ (í´ë°±ìš©)
        minio_bucket: MinIO ë²„í‚· ì´ë¦„ (í´ë°±ìš©)
        
    Returns:
        Dict: ì €ì¥ ì •ë³´ (run_id, model_uri, version ë“±)
    """
    try:
        import mlflow
        import mlflow.sklearn
        from mlflow.tracking import MlflowClient
        import tempfile
        
        if use_mlflow:
            # MLflow ì„œë²„ ì—°ê²° ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
            import requests
            import time
            max_retries = 30
            retry_interval = 2
            
            for i in range(max_retries):
                try:
                    response = requests.get(f"{mlflow_tracking_uri}/health", timeout=2)
                    if response.status_code == 200:
                        print(f"âœ… MLflow ì„œë²„ ì—°ê²° ì„±ê³µ")
                        break
                except Exception as e:
                    if i < max_retries - 1:
                        print(f"â³ MLflow ì„œë²„ ì—°ê²° ëŒ€ê¸° ì¤‘... ({i+1}/{max_retries})")
                        time.sleep(retry_interval)
                    else:
                        raise ConnectionError(f"MLflow ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mlflow_tracking_uri}")
            
            # MLflow ì„¤ì •
            mlflow.set_tracking_uri(mlflow_tracking_uri)
            
            # ì‹¤í—˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            # client = MlflowClient(tracking_uri=mlflow_tracking_uri)
            # try:
            #     # ì‹¤í—˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            #     experiment = client.get_experiment_by_name(experiment_name)
            #     if experiment is None:
            #         # ì‹¤í—˜ì´ ì—†ìœ¼ë©´ ìƒì„±
            #         print(f"ğŸ“ ì‹¤í—˜ '{experiment_name}' ìƒì„± ì¤‘...")
            #         experiment_id = client.create_experiment(experiment_name)
            #         print(f"âœ… ì‹¤í—˜ ìƒì„± ì™„ë£Œ (ID: {experiment_id})")
            #     else:
            #         print(f"âœ… ì‹¤í—˜ '{experiment_name}' ì¡´ì¬ í™•ì¸ (ID: {experiment.experiment_id})")
            # except Exception as e:
            #     # ì‹¤í—˜ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ set_experimentë¡œ ì‹œë„ (ìë™ ìƒì„±)
            #     print(f"âš ï¸ ì‹¤í—˜ ì¡°íšŒ ì‹¤íŒ¨, ìë™ ìƒì„± ì‹œë„: {str(e)}")
            #     mlflow.set_experiment(experiment_name)
            # else:
            #     # ì‹¤í—˜ ì„¤ì •
            #     mlflow.set_experiment(experiment_name)
          
            mlflow.set_experiment(experiment_name)

            with mlflow.start_run() as run:
                # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
                mlflow.log_params(hyperparameters)
                
                # ë©”íŠ¸ë¦­ ë¡œê¹…
                mlflow.log_metrics(metrics)
                
                # ë°ì´í„° ì •ë³´ ë¡œê¹…
                mlflow.log_params({
                    f"data_{k}": str(v) for k, v in data_info.items()
                })
                
                # ì¸ì½”ë” ì €ì¥ (artifacts)
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp_file:
                    pickle.dump(encoders, tmp_file)
                    tmp_file.flush()
                    mlflow.log_artifact(tmp_file.name, "encoders")
                    os.unlink(tmp_file.name)
                
                # ëª¨ë¸ ì €ì¥ ë° ë“±ë¡
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                unique_model_name = f"{model_name}_{timestamp}"
                mlflow.sklearn.log_model(
                    model,
                    "model",
                    registered_model_name=unique_model_name
                )
                
                # ë©”íƒ€ë°ì´í„° ì €ì¥
                metadata = {
                    "model_name": unique_model_name,
                    "run_id": run.info.run_id,
                    "experiment_id": run.info.experiment_id,
                    "created_at": datetime.now().isoformat(),
                    "data_info": data_info
                }
                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json', encoding='utf-8') as tmp_file:
                    json.dump(metadata, tmp_file, indent=2, ensure_ascii=False)
                    tmp_file.flush()
                    mlflow.log_artifact(tmp_file.name, "metadata")
                    os.unlink(tmp_file.name)
                
                # ëª¨ë¸ ë“±ë¡ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                client = MlflowClient(tracking_uri=mlflow_tracking_uri)
                model_versions = client.get_latest_versions(model_name, stages=["None"])
                if model_versions:
                    model_version = model_versions[0]
                else:
                    # ëª¨ë¸ì´ ë“±ë¡ë˜ì§€ ì•Šì€ ê²½ìš° (ì´ë¡ ì ìœ¼ë¡œëŠ” ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨)
                    model_version = None
                
                result = {
                    "run_id": run.info.run_id,
                    "model_uri": f"runs:/{run.info.run_id}/model",
                    "model_version": model_version.version if model_version else "unknown",
                    "experiment_id": run.info.experiment_id,
                    "storage_type": "mlflow"
                }
                
                print(f"âœ… MLflow ì €ì¥ ì™„ë£Œ")
                print(f"   Run ID: {run.info.run_id}")
                if model_version:
                    print(f"   Model Version: {model_version.version}")
                print(f"   Model URI: {result['model_uri']}")
                
                return result
                
    except Exception as e:
        print(f"âš ï¸ MLflow ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        if fallback_to_minio and minio_client and minio_bucket:
            print("ğŸ“¦ MinIOë¡œ í´ë°± ì €ì¥ ì¤‘...")
            model_path = save_artifacts_to_minio(
                client=minio_client,
                bucket=minio_bucket,
                model=model,
                encoders=encoders,
                metrics=metrics,
                model_name=model_name,
                hyperparameters=hyperparameters,
                data_info=data_info
            )
            result = {
                "model_path": model_path,
                "storage_type": "minio_fallback",
                "error": str(e)
            }
            return result
        else:
            raise


def train_model(
    minio_endpoint: str = 'minio:9000',
    minio_access_key: str = 'minio',
    minio_secret_key: str = 'minio123',
    minio_bucket: str = "raw",
    data_object: str = 'Apart_Deal.csv',
    model_bucket: str = "models",
    mlflow_tracking_uri: Optional[str] = None,
    use_mlflow: bool = False,
    data_limit: Optional[int] = 15000,
    test_size: float = 0.2,
    random_state: int = 42,
    n_estimators: int = 100,
    save_model: bool = True
) -> Dict[str, float]:
    """
    ëª¨ë¸ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜
    
    Args:
        minio_endpoint: MinIO ì—”ë“œí¬ì¸íŠ¸
        minio_access_key: MinIO ì ‘ê·¼ í‚¤
        minio_secret_key: MinIO ì‹œí¬ë¦¿ í‚¤
        minio_bucket: ë°ì´í„° ë²„í‚· ì´ë¦„
        data_object: ë°ì´í„° ê°ì²´ ì´ë¦„
        model_bucket: ëª¨ë¸ ì €ì¥ ë²„í‚· ì´ë¦„
        mlflow_tracking_uri: MLflow ì„œë²„ URI (ì˜ˆ: "http://mlflow:5000")
        use_mlflow: MLflow ì‚¬ìš© ì—¬ë¶€
        data_limit: ë°ì´í„° ì œí•œ í–‰ ìˆ˜
        test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        random_state: ëœë¤ ì‹œë“œ
        n_estimators: ëœë¤ í¬ë ˆìŠ¤íŠ¸ íŠ¸ë¦¬ ê°œìˆ˜
        save_model: ëª¨ë¸ ì €ì¥ ì—¬ë¶€
        
    Returns:
        Dict[str, float]: í‰ê°€ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # MinIO í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = get_minio_client(
            endpoint=minio_endpoint,
            access_key=minio_access_key,
            secret_key=minio_secret_key
        )
        
        # ë°ì´í„° ë¡œë“œ
        print(f"ë°ì´í„° ë¡œë“œ ì¤‘: {minio_bucket}/{data_object}")
        df = load_data_from_minio(client, minio_bucket, data_object, limit=data_limit)
        print(f"ë¡œë“œëœ ë°ì´í„° í–‰ ìˆ˜: {len(df)}")
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        print("ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        n_df_pd, encoders = preprocess_data(df)
        print(f"ì „ì²˜ë¦¬ ì™„ë£Œ. ì»¬ëŸ¼ ìˆ˜: {len(n_df_pd.columns)}")
        
        # íƒ€ê²Ÿê³¼ í”¼ì²˜ ë¶„ë¦¬
        y = n_df_pd['ê±°ë˜ê¸ˆì•¡']
        X = n_df_pd.drop(columns=['ê±°ë˜ê¸ˆì•¡'])
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        print(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}í–‰, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}í–‰")
        
        # ëª¨ë¸ í•™ìŠµ
        print("ëª¨ë¸ í•™ìŠµ ì¤‘...")
        rfc = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)
        rfc.fit(X_train, y_train)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = rfc.predict(X_test)
        
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # ê±°ë˜ê¸ˆì•¡ í†µê³„
        y_mean = y_test.mean()
        y_std = y_test.std()
        
        metrics = {
            'mse': float(mse),
            'rmse': float(rmse),
            'mae': float(mae),
            'r2': float(r2),
            'y_mean': float(y_mean),
            'y_std': float(y_std),
            'y_min': float(y_test.min()),
            'y_max': float(y_test.max()),
            'rmse_percentage': float((rmse/y_mean)*100),
            'mae_percentage': float((mae/y_mean)*100)
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print("=" * 50)
        print("ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ")
        print("=" * 50)
        print(f"MSE (Mean Squared Error): {mse:,.2f}")
        print(f"RMSE (Root Mean Squared Error): {rmse:,.2f} ë§Œì›")
        print(f"MAE (Mean Absolute Error): {mae:,.2f} ë§Œì›")
        print(f"RÂ² Score: {r2:.4f}")
        print()
        print("=" * 50)
        print("ì‹¤ì œ ê±°ë˜ê¸ˆì•¡ í†µê³„")
        print("=" * 50)
        print(f"í‰ê· : {y_mean:,.2f} ë§Œì›")
        print(f"í‘œì¤€í¸ì°¨: {y_std:,.2f} ë§Œì›")
        print(f"ìµœì†Œê°’: {y_test.min():,} ë§Œì›")
        print(f"ìµœëŒ€ê°’: {y_test.max():,} ë§Œì›")
        print()
        print("=" * 50)
        print("ìƒëŒ€ì  ì„±ëŠ¥")
        print("=" * 50)
        print(f"RMSE / í‰ê· : {(rmse/y_mean)*100:.2f}%")
        print(f"MAE / í‰ê· : {(mae/y_mean)*100:.2f}%")
        print(f"RÂ² Score: {r2:.4f} ({r2*100:.2f}% ì„¤ëª…ë ¥)")
        
        # ëª¨ë¸ ì €ì¥
        if save_model:
            print("\nëª¨ë¸ ì €ì¥ ì¤‘...")
            
            hyperparameters = {
                "n_estimators": n_estimators,
                "random_state": random_state,
                "test_size": test_size
            }
            
            data_info = {
                "train_size": len(X_train),
                "test_size": len(X_test),
                "features": list(X.columns),
                "data_limit": data_limit
            }
            
            if use_mlflow and mlflow_tracking_uri:
                # MLflow ì‚¬ìš© (í•˜ì´ë¸Œë¦¬ë“œ: ì‹¤íŒ¨ ì‹œ MinIO í´ë°±)
                storage_info = save_artifacts_with_mlflow(
                    mlflow_tracking_uri=mlflow_tracking_uri,
                    model=rfc,
                    encoders=encoders,
                    metrics=metrics,
                    hyperparameters=hyperparameters,
                    data_info=data_info,
                    model_name="apartment-price-prediction",
                    experiment_name="apartment-price-prediction",
                    use_mlflow=True,
                    fallback_to_minio=True,
                    minio_client=client,
                    minio_bucket=model_bucket
                )
                print(f"ğŸ“¦ ì €ì¥ ì •ë³´: {storage_info}")
            else:
                # MinIO ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
                model_path = save_artifacts_to_minio(
                    client=client,
                    bucket=model_bucket,
                    model=rfc,
                    encoders=encoders,
                    metrics=metrics,
                    model_name="apartment-price-prediction",
                    version=None,  # ìë™ ìƒì„±
                    hyperparameters=hyperparameters,
                    data_info=data_info
                )
                print(f"ğŸ“¦ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_path}")
        
        return metrics
        
    except Exception as e:
        print(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise


# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    train_model()
